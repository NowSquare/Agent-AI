# ==============================================================================
# Agent-AI — Docker (Dev/Prod)
# ==============================================================================

APP_NAME="Agent AI"
APP_ENV=local
APP_DEBUG=true
APP_URL="http://localhost:8080"
APP_TIMEZONE="Europe/Amsterdam"

# PostgreSQL (container)
DB_CONNECTION=pgsql
DB_HOST=postgres
DB_PORT=5432
DB_DATABASE=agent_ai
DB_USERNAME=agent_user
DB_PASSWORD="your_secure_password"

# Redis (container)
CACHE_DRIVER=redis
SESSION_DRIVER=redis
QUEUE_CONNECTION=redis
REDIS_HOST=redis
REDIS_PORT=6379

# Postmark
MAIL_MAILER="postmark"
POSTMARK_TOKEN="your-real-postmark-server-token"
POSTMARK_MESSAGE_STREAM_ID="outbound"
MAIL_FROM_ADDRESS="noreply@agent-ai.test"
MAIL_FROM_NAME="Agent AI"

# Inbound webhook (Postmark → Basic Auth)
AGENT_MAIL="<hash>@inbound.postmarkapp.com"
WEBHOOK_USER="postmark"
WEBHOOK_PASS="your-very-long-random-password-here"

# LLM — Routing & Roles
LLM_TIMEOUT_MS=120000
LLM_RETRY_MAX=1
LLM_ROUTING_MODE=auto
LLM_GROUNDING_HIT_MIN=0.35
LLM_SYNTH_COMPLEXITY_TOKENS=1200
LLM_MAX_AGENT_STEPS=10

LLM_CLASSIFY_PROVIDER=ollama
LLM_CLASSIFY_MODEL="mistral-small3.2:24b"
LLM_CLASSIFY_TOOLS=true
LLM_CLASSIFY_REASONING=false

LLM_GROUNDED_PROVIDER=ollama
LLM_GROUNDED_MODEL="qwen3:14b"
LLM_GROUNDED_TOOLS=true
LLM_GROUNDED_REASONING=false

LLM_SYNTH_PROVIDER=ollama
LLM_SYNTH_MODEL="deepseek-v3.1:32b"
LLM_SYNTH_TOOLS=true
LLM_SYNTH_REASONING=true

# Embeddings (pgvector)
EMBEDDINGS_PROVIDER=ollama
EMBEDDINGS_MODEL="mxbai-embed-large"
EMBEDDINGS_DIM=1024
EMBEDDINGS_DISTANCE=cosine
EMBEDDINGS_INDEX_LISTS=100

# Providers
OLLAMA_BASE_URL="http://ollama:11434"
OPENAI_API_KEY=
OPENAI_BASE_URL="https://api.openai.com/v1"
ANTHROPIC_API_KEY=
ANTHROPIC_BASE_URL="https://api.anthropic.com"

# ClamAV (container)
CLAMAV_HOST=clamav
CLAMAV_PORT=3310

ATTACH_MAX_SIZE_MB=25
ATTACH_TOTAL_MAX_SIZE_MB=40
FILESYSTEM_DISK=local
